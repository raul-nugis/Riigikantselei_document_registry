{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"https://i0.wp.com/kpmgeestiblog.ee/wp-content/uploads/2018/12/cropped-LOGIO_KPMG_NoCP_RGB_280-2.png?resize=110%2C51&ssl=1\"> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-mining document registry\n",
    "\n",
    "\n",
    "#### The purpose of this notebook is to quickly:\n",
    "1. Review Riigikantselei's (Chancellory of Government Office of Estonia) public Document Registry, \n",
    "2. Understand structure of document entries and define several sample fields (like type of document, direction of document flow, date etc),\n",
    "3. Devise functions to web-scrape contents - intentionally at very limited scope,\n",
    "4. Run a scraper for last full month (May) and save results as structured date to table file,\n",
    "6. Check results.\n",
    "\n",
    "The time-frame to devise and implement scraper is 1-2 hours\n",
    "\n",
    "link to registry:\n",
    "https://dhs.riigikantselei.ee/avalikteave.nsf/byjournalkey?open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Review Riigikantselei's (Chancellory of Government Office of Estonia) public Document Registry\n",
    "\n",
    "The registry has comprehensive search engine\n",
    "<br>The registry has got customized html tags like\n",
    "\n",
    "<br><i>&lt;fieldtitle name=\"receivedfrom\">Kellelt saabunud&lt;/fieldtitle></i>\n",
    "\n",
    "<br>The registry uses HEX numbering to generate links to documents\n",
    "\n",
    "<i>\"https://dhs.riigikantselei.ee/avalikteave.nsf/documents/NT003822E6\"</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Understand structure of document entries and define several sample fields\n",
    "\n",
    "The fields can be parsed out by manipulated html text. This is less ideal than using Beautiful Soup functionalities, especially to parse out HTML tables. However, Riigikatselei's document registry uses completely customized tags for tables, instead of standard one and digging into them is a must. Also, there are only certain fields to be taken for this particular business task (defined in point 3 above), such as receivers, senders, type of document and very few others.\n",
    "\n",
    "#### 3. Devise functions to web-scrape contents\n",
    "\n",
    "The fields are defined in a .py module \"riigikantselei_functions\"\n",
    "<br>There are several functions from this module, visible below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined:\n",
      "\n",
      " get_web_contents(link)\t\t\treturns \"contents\"\n",
      " get_links(soup)\t\t\treturns \"links\"\n",
      " parse_entry(contents, url, counter)\treturns \"dataframe\"\n",
      " generate_hexes(hex_code = \"37E2A2\")\treturns \"hex links\"\n",
      " scrape_web(links)\t\t\tsaves web scraped contents to Excel file\n"
     ]
    }
   ],
   "source": [
    "import riigikantselei_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fields to scrape and place to table format are defined inside function\n",
    "\"parse_entry\" and can be printed from inner help of that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function parse_entry in module riigikantselei_functions:\n",
      "\n",
      "parse_entry(contents, url, counter)\n",
      "    This function parses out the contents of one document entry in Document Registry\n",
      "    The idea is to use ad-hoc functionalities based on text manipulation and obtain values \n",
      "    for only select fields, which are:\n",
      "                         columns = ['URL',\n",
      "                                'Kellelt',\n",
      "                                'Kellele',\n",
      "                                'V채ljaandja',\n",
      "                                'Dok No', \n",
      "                                'Kuup채ev',\n",
      "                                'Dok T체체p', \n",
      "                                'Dok Klass', \n",
      "                                'AK']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from riigikantselei_functions import get_web_contents, get_links, parse_entry, generate_hexes, scrape_web\n",
    "\n",
    "help(parse_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run a scraper for last full month (May 2021) and save results as structured date to table file\n",
    "\n",
    "As mentioned above, Riigikantselei has chosen - in addition to html tags customization - also customized links by replacing normal decimal incrementation with HEX incrementation. Therefore in the below code I create some 16341 links, which encompass May 2021, and which use HEX incrementation\n",
    "\n",
    "The initial link is based on patterns of links in the first few days of May, which were found by manual review. 16K additional links generated are very much likely to contain all of the document turnover registered in the registry in May 2021, the whole month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_links = generate_hexes(hex_code = \"37E2A2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 16 links, starting from the beginning of May were created, I also create 15K links goint to the past, to be sure that no links were missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_links_prev = generate_hexes(hex_code = '37A80A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will web scrape 16K links that were just automatically generated, parse all documents to predifined tabel and save results to MS Excel XLSX files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing scraping... 20:51:44\n",
      "Saving.. 11_06_2021_20_54_52_408_temp_.xlsx on 408 iteration 20:54:52\n",
      "Saving.. 11_06_2021_20_58_04_812_temp_.xlsx on 812 iteration 20:58:05\n",
      "Saving.. 11_06_2021_21_01_16_1212_temp_.xlsx on 1212 iteration 21:01:16\n",
      "Saving.. 11_06_2021_22_03_03_7720_temp_.xlsx on 7720 iteration 22:03:03\n",
      "Saving.. 11_06_2021_22_06_09_8128_temp_.xlsx on 8128 iteration 22:06:09\n",
      "Saving.. 11_06_2021_22_09_12_8532_temp_.xlsx on 8532 iteration 22:09:12\n",
      "Saving.. 11_06_2021_22_12_12_8932_temp_.xlsx on 8932 iteration 22:12:12\n",
      "Saving.. 11_06_2021_22_15_15_9336_temp_.xlsx on 9336 iteration 22:15:15\n",
      "Saving.. 11_06_2021_23_14_19_15836_temp_.xlsx on 15836 iteration 23:14:19\n",
      "Saving.. 11_06_2021_23_17_19_16240_temp_.xlsx on 16240 iteration 23:17:19\n",
      "Saving.. 11_06_2021_23_18_08_16341_FINAL_.xlsx on 16341 iteration\n",
      "Scraping completed with 16341 runs altogether 1025 collected 23:18:09\n"
     ]
    }
   ],
   "source": [
    "scrape_web(generated_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will additionally web scrape 15K links that were just automatically generated, parse all documents to predifined tabel and save results to MS Excel XLSX files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing scraping... 09:37:02\n",
      "Saving.. 12_06_2021_10_00_30_2636_temp_.xlsx on 2636 iteration 10:00:30\n",
      "Saving.. 12_06_2021_10_03_37_3040_temp_.xlsx on 3040 iteration 10:03:37\n",
      "Saving.. 12_06_2021_10_06_43_3444_temp_.xlsx on 3444 iteration 10:06:43\n",
      "Saving.. 12_06_2021_10_09_49_3848_temp_.xlsx on 3848 iteration 10:09:49\n",
      "Saving.. 12_06_2021_10_12_51_4248_temp_.xlsx on 4248 iteration 10:12:51\n",
      "Saving.. 12_06_2021_10_53_14_8712_temp_.xlsx on 8712 iteration 10:53:15\n",
      "Saving.. 12_06_2021_10_56_17_9112_temp_.xlsx on 9112 iteration 10:56:17\n",
      "Saving.. 12_06_2021_10_59_19_9512_temp_.xlsx on 9512 iteration 10:59:20\n",
      "Saving.. 12_06_2021_11_02_33_9920_temp_.xlsx on 9920 iteration 11:02:34\n",
      "Saving.. 12_06_2021_11_05_38_10320_temp_.xlsx on 10320 iteration 11:05:39\n",
      "Saving.. 12_06_2021_11_46_05_14792_temp_.xlsx on 14792 iteration 11:46:05\n",
      "Saving.. 12_06_2021_11_47_45_15000_FINAL_.xlsx on 15000 iteration\n",
      "Scraping completed with 15000 runs altogether 1151 collected 11:47:45\n"
     ]
    }
   ],
   "source": [
    "scrape_web(generated_links_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check results\n",
    "I wil check results of downloaded files to see if a nice table format was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Kellelt</th>\n",
       "      <th>Kellele</th>\n",
       "      <th>V채ljaandja</th>\n",
       "      <th>Dok No</th>\n",
       "      <th>Kuup채ev</th>\n",
       "      <th>Dok T체체p</th>\n",
       "      <th>Dok Klass</th>\n",
       "      <th>AK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>https://dhs.riigikantselei.ee/avalikteave.nsf/...</td>\n",
       "      <td></td>\n",
       "      <td>Kandidaat</td>\n",
       "      <td></td>\n",
       "      <td>21-00376-10</td>\n",
       "      <td>07.05.2021</td>\n",
       "      <td>Kiri</td>\n",
       "      <td>18 Avaliku teenistuse tippjuhtide v채rbamine ja...</td>\n",
       "      <td>Asutusesiseseks kasutamiseks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>https://dhs.riigikantselei.ee/avalikteave.nsf/...</td>\n",
       "      <td>Justiitsministeerium</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>21-01098-1</td>\n",
       "      <td>07.05.2021</td>\n",
       "      <td>M채채ruse eeln천u</td>\n",
       "      <td>02 Vabariigi Valitsuse istungite ja n천upidamis...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>https://dhs.riigikantselei.ee/avalikteave.nsf/...</td>\n",
       "      <td>L채채ne-Viru Omavalitsuste Liit</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>21-01094-1</td>\n",
       "      <td>06.05.2021</td>\n",
       "      <td>Kiri</td>\n",
       "      <td>07 Vabariigi Valitsuse ja peaministri muu asja...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  \\\n",
       "200  https://dhs.riigikantselei.ee/avalikteave.nsf/...   \n",
       "201  https://dhs.riigikantselei.ee/avalikteave.nsf/...   \n",
       "202  https://dhs.riigikantselei.ee/avalikteave.nsf/...   \n",
       "\n",
       "                           Kellelt    Kellele V채ljaandja       Dok No  \\\n",
       "200                                 Kandidaat             21-00376-10   \n",
       "201           Justiitsministeerium                         21-01098-1   \n",
       "202  L채채ne-Viru Omavalitsuste Liit                         21-01094-1   \n",
       "\n",
       "        Kuup채ev        Dok T체체p  \\\n",
       "200  07.05.2021            Kiri   \n",
       "201  07.05.2021  M채채ruse eeln천u   \n",
       "202  06.05.2021            Kiri   \n",
       "\n",
       "                                             Dok Klass  \\\n",
       "200  18 Avaliku teenistuse tippjuhtide v채rbamine ja...   \n",
       "201  02 Vabariigi Valitsuse istungite ja n천upidamis...   \n",
       "202  07 Vabariigi Valitsuse ja peaministri muu asja...   \n",
       "\n",
       "                               AK  \n",
       "200  Asutusesiseseks kasutamiseks  \n",
       "201                                \n",
       "202                                "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['URL','Kellelt','Kellele','V채ljaandja','Dok No','Kuup채ev','Dok T체체p','Dok Klass','AK']\n",
    "pd.read_excel('11_06_2021_23_18_08_16341_FINAL_.xlsx')[columns][200:203].fillna('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
